{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["Data manipulation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import nltk"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk.corpus import stopwords\n", "from nltk.stem import WordNetLemmatizer"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plotting"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main() -> None:\n", "    #Loading dataset\n", "    df = pd.read_csv(\"dataset.csv\", delimiter=',')\n\n", "    #Building up data for plotting\n", "    categories = df[\"CATEGORY\"].unique()\n", "    data = {}\n", "    for category in categories:\n", "        data[category] = 0\n", "    for cat in df[\"CATEGORY\"]:\n", "        data[cat] += 1\n\n", "    #Getting dataset composition\n", "    names = list(data.keys())\n", "    values = list(data.values())\n", "    \n", "    #Plotting dataset composition\n", "    print(names)\n", "    \n", "    plt.bar(names[0], values[0], color=\"blue\", label=names[0])\n", "    plt.bar(names[1], values[1], color=\"red\", label=names[1])\n", "    plt.bar(names[2], values[2], color=\"black\", label=names[2])\n", "    plt.bar(names[3], values[3], color=\"green\", label=names[3])\n", "    plt.bar(names[4], values[4], color=\"yellow\", label=names[4])\n", "    plt.bar(names[5], values[5], color=\"orange\", label=names[5])\n", "    plt.xlabel(\"Categories\")\n", "    plt.ylabel(\"Size\")\n", "    plt.title(\"Dataset composition\")\n", "    plt.legend()\n", "    plt.grid()\n", "    plt.show()\n\n", "    #Special characted cleaning\n", "    df[\"F_CONTENT\"] = df[\"F_CONTENT\"].str.replace(\"'s\", \"\")\n", "    df[\"F_CONTENT\"] = df[\"F_CONTENT\"].str.replace(\"\u2019s\", \"\")\n", "    df[\"F_CONTENT\"] = df[\"F_CONTENT\"].str.strip().str.lower().str.replace('\"','')\n", "    for punct_sign in list(\"?:!.,;'\u2019\"):\n", "        df[\"F_CONTENT\"] = df[\"F_CONTENT\"].str.replace(punct_sign, ' ')\n", "    \n", "    nltk.download('punkt')\n", "    nltk.download('wordnet')\n\n", "    #Lemmatization\n", "    wordnet_lemmatizer = WordNetLemmatizer()\n", "    lemmatized_text_list = []\n", "    for row in range(len(df)):\n", "        lemmatized_list = []\n", "        text = df.loc[row][\"F_CONTENT\"]\n", "        text_words = text.split(\" \")\n", "        for word in text_words:\n", "            lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n", "        \n", "        lemmatized_text_list.append(\" \".join(lemmatized_list))\n", "    df[\"F_CONTENT\"] = lemmatized_text_list\n", "   \n", "    #Stopwords\n", "    nltk.download('stopwords')\n", "    stop_words = list(stopwords.words('english'))\n", "    for stop_word in stop_words:\n", "        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n", "        df[\"F_CONTENT\"] = df[\"F_CONTENT\"].str.replace(regex_stopword, '')\n", "    print(df[\"F_CONTENT\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}